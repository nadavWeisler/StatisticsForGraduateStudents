---
title: "Final Project"
author: "Nadav Weisler - 316493758, Gaya Aran - 209636885"
output: html_document
---

```{r warning=FALSE}
require(rjson)
require(corrplot)
require(ez)
require(lsr)
require(DescTools)
require(sciplot)
require(pwr)
require(WebPower)
require(effectsize)
require(sjPlot)
```

```{r}
# setwd("SOME_PATH")
```

# Part 1: Describing the design and dataset [7 points overall]

## 1.1 [300 words overall; 7 points]

Describe the research question, design, and dataset, following the sub-questions 
below. You can also include a figure to describe the design/task, if helpful. 

### 1.1.1 
What was the study’s main research question?

### 1.1.2
What was the study type (i.e., correlational, or experimental2)? Was it a 
between subject or within-subject design?

### 1.1.3 
What were the task(s) used, and the experimental conditions in the task 
(if any)? How many stimuli and trials were included? Was the data longitudinal
(i.e., collected at multiple time-points)?

### 1.1.4 
What were the study’s variables? Refer to independent variable(s), control
variable(s), and dependent variable(s).

### 1.1.5
Who were the participants in the sample and what was the sample size? How was
sample size originally determined?

### 1.1.6 
Are there any other methodological details you think we should know about for 
us to understand the rest of this assignment?

# Part 2: What was done already? [45 points overall]

## 2.1 [80 words; 4 points]

How was the data previously cleaned and pre-processed? Were any observations
(at the participant- or trial-level) removed? Based on what criteria? Were any transformations applied to variables? Briefly describe the processes applied, pertaining to these questions and others you deem relevant.

## 2.2 [4 points]

Repeat the exact data cleaning procedure using your own code. Submit the code with detailed comments. 

```{r}
# Load data file
prev_df = read.csv("data.csv")
```

```{r}
prev_df$stimulus_block[prev_df$stimulus_block == "5Where"] = "6Where"
prev_df$stimulus_block[prev_df$stimulus_block == "5What"] = "6What"

# Create blocks name vector for future use
blockNames = c('10controlWhere', '10Where', '6Where','6What', '10What')
```

```{r}
# Function that fix subjects and correctness
getSubjectAndCorrectness = function(df) {
  # Current subject indicator
  currentSubject = 0
  # Create isAnsCorrect column
  df$isAnsCorrect = 0
  # For each row in data frame
  for(i in 1:nrow(df)) {
    # Fix subjects column
    # New subject started
    if(df[i, "trial_index"] == 0) {
      # Append 1 to currentSubject
      currentSubject = currentSubject + 1
    }
    # Set subject column to relevant subject
    df[i, "subject"] = currentSubject
    
    # Create isAnsCorrect column - If subject where correct in RMS task
    # If this trial is one of the RMS blocks
    if(is.element(df[i, "stimulus_block"], blockNames)) {
      # If its where condition
      if(endsWith(df[i, "stimulus_block"], "Where")) {
        # If it is correct (left side)
        if ((df[i, "key_press"] == "Q") & 
            (df[i, "stimulus_side"] == 1)) {
          # Set 1 to isAnsCorrect
          df[i, "isAnsCorrect"] = 1
        } 
        # If it is correct (right side) 
        else if ((df[i, "key_press"] == "P") & 
                 (df[i, "stimulus_side"] == 0)) {
          # Set 1 to isAnsCorrect
          df[i, "isAnsCorrect"] = 1
        } 
        # If it is missed (no response)
        else if (df[i, "key_press"] == -1){
          # Set -1 to isAnsCorrect
          df[i, "isAnsCorrect"] = -1
        } 
        # Else (wrong answer remains)
        else {
          # Set 0 to isAnsCorrect
          df[i, "isAnsCorrect"] = 0
        }
      } 
      # If its where condition
      else if(endsWith(df[i, "stimulus_block"], "What")) {
        # If it is correct (straight face)
        if ((df[i, "key_press"] == "Y") & 
            (startsWith(df[i, "stimulus"], "f"))) {
          # Set 1 to isAnsCorrect
          df[i, "isAnsCorrect"] = 1
        } 
        # If it is correct (inverted face)
        else if ((df[i, "key_press"] == "B") & 
                 (startsWith(df[i, "stimulus"], "d"))) {
          # Set 1 to isAnsCorrect
          df[i, "isAnsCorrect"] = 1
        } 
        # If it is missed (no response)
        else if (df[i, "key_press"] == -1){
          # Set -1 to isAnsCorrect
          df[i, "isAnsCorrect"] = -1
        } 
        # Else (wrong answer remains)
        else {
          # Set 0 to isAnsCorrect
          df[i, "isAnsCorrect"] = 0
        }
      }
    }
  }
  # Return fixed df with correctness
  return(df)
}
```

```{r}
prev_df = getSubjectAndCorrectness(prev_df)
```

```{r}
# Create getAccResult function, get data frame and indication if add
# control to the calculation, return Accuracy calculation that:
# Correct answers / all Answers
getAccResult = function(single_df, remove_control = F) {
  # If remove_control is true
  if(remove_control) {
    # Remove control trials from single_df
    single_df = single_df[single_df$stimulus_block != "10controlWhere",]
  } 
  # Get all incorrect and missed trials row count
  incorrect = nrow(single_df[(single_df$isAnsCorrect == 0) |
                             (single_df$isAnsCorrect == -1),])
  # Get all correct trials row count
  correct = nrow(single_df[single_df$isAnsCorrect == 1,])
  # Return accuracy result
  return((correct / (correct + incorrect)))
}
```

```{r}
# Get Missed results percent count get single_df and return missed
# results represent as missed trials count / all trial count
getMissedResult = function(single_df) {
    # Get all trials count
    all_rms_count = nrow(single_df[(single_df$isAnsCorrect == 0) | 
                                (single_df$isAnsCorrect == 1) |
                                (single_df$isAnsCorrect == -1), ])
    # Get missed trials count
    rms_misses = nrow(single_df[single_df$isAnsCorrect == -1, ])
    # return missed results
    return(rms_misses / all_rms_count)
}
```

```{r}
# Get Face inversion effect (mean of straight face minus mean of revert
# face) function, get data frame and Boolean log Return face inversion 
# effect, log values of log is true 
getFaceInversionMean = function(single_df, log=F) {
  # Get mean of rt when face is straight
  mainFaces = mean(single_df[startsWith(single_df$stimulus, "f"), ]$rt)
  # Get mean of rt when face is revert
  revertFaces = mean(single_df[startsWith(single_df$stimulus, "d"), ]$rt)
  # If log is true
  if(log) {
    # Return face inversion of log values, log rt of straight faces
    # and log rt of revert faces
    return(c(log10(mainFaces) - log10(revertFaces), 
             log(mainFaces), log10(revertFaces)))
  } else {
    # Return face inversion, rt of straight faces and rt of revert faces
    return(c(mainFaces - revertFaces, mainFaces, revertFaces))
  }
}
```

```{r}
# Get clean block data frame
getCleanInTrialDf = function(block_df) {
  # Only correct
  current_df = block_df[block_df$isAnsCorrect == 1, ]
  # Bigger than the threshold 200 ms
  current_df = current_df[current_df$rt > 200,]
  # Create scaled RT
  current_df$scaledRT = scale(current_df$rt)
  # Remove trials with rt bigger than mean +- 3 SD
  current_df = current_df[abs(current_df$scaledRT) < 3,]
  # Return clean data frame
  return(current_df)
}
```

```{r}
# Get all values for single block, get data frame and block name
# and return vector of all results for this block in this data frame
getAllValuesPerBlock = function(single_df, block_name, subject_id) {
  # Only in the relevant block
  block_df = single_df[single_df$stimulus_block == block_name,] 
  # Get clean block data frame
  current_df = getCleanInTrialDf(block_df)
  # Init results vector
  result = c()
  # Add rt mean
  result = c(result, mean(current_df$rt))
  # Add rt SD
  result = c(result, sd(current_df$rt))
  # Add accuracy
  result = c(result, getAccResult(block_df))
  # Add misses
  result = c(result, getMissedResult(block_df))
  # Add rt mean of incorrect trials
  result = c(result, mean(block_df[block_df$isAnsCorrect == 0,]$rt))
  # Get face inversion effect results
  face_inversion_values = getFaceInversionMean(block_df)
  # Add face inversion value
  result = c(result, face_inversion_values[1])
  # Add straight faces mean rt
  result = c(result, face_inversion_values[2])
  # Add reverted faces mean rt
  result = c(result, face_inversion_values[3])
  # Add rt mean log value
  result = c(result, log(mean(current_df$rt)))
  # Add rt SD log value
  result = c(result, log(sd(current_df$rt)))
  # Get log face inversion values
  face_inversion_log_values = getFaceInversionMean(current_df, T)
  # Add log face inversion value
  result = c(result, face_inversion_values[1])
  # Add log straight faces mean rt
  result = c(result, face_inversion_values[2])
  # Add log revert faces mean rt
  result = c(result, face_inversion_values[3])
  # Return result vector
  return(result)
}
```

```{r}
# Get online id and age from data frame, return it in vector
getOnlineIdAndAge = function(single_df) {
  # Create subset of single_df called text_df which contains only
  # survey-text trials
  text_df = single_df[single_df$trial_type == "survey-text", ]
  # Create online_id variable
  online_id = 0
  # Create age variable
  age = 0
  # For each row in text_df
  for(i in 1:nrow(text_df)) {
    # If there is a response
    if(text_df[i, "responses"] != "") {
      # Parse response to object called value
      value = fromJSON(text_df[i, "responses"])
      # If response length bigger than 2 its the online_id
      if(nchar(value$Q0) > 2) {
        # set online_id variable
        online_id = value$Q0
      } else {
        # Set age variable
        age = value$Q0
      }
    } 
  }
  # return online_id and age in vector
  return(c(online_id, age))
}
```

```{r}
# Get results vector of all blocks from single_df data frame
getAllBlocksValue = function(single_df, subject_id) {
  # Init of result vector
  result = c()
  # For each block in blockNames vector
  for(block in blockNames) {
    # Add the output vector of getAllValuesPerBlock of the current block
    # to the results vector
    result = c(result, getAllValuesPerBlock(single_df, block, subject_id))
  }
  # Return result vector
  return(result)
}
```

```{r}
# Get result vector of single subject, get data frame and subject id
getSingleSubject = function(df, subject_id) {
  # Get subset of df called current_subject_df contains all trials of
  # the given subject
  current_subject_df = df[df$subject == subject_id,]
  # Init result row
  row = c()
  # Add subject ID
  row = c(row, subject_id)
  # Add online ID and age
  row = c(row, getOnlineIdAndAge(current_subject_df))
  # Add general accuracy
  row = c(row, getAccResult(current_subject_df))
  # Add general accuracy without control
  row = c(row, getAccResult(current_subject_df, T))
  # Add general missed results
  row = c(row, getMissedResult(current_subject_df))
  # Add all other values returned in getAllBlocksValue
  row = c(row, getAllBlocksValue(current_subject_df, subject_id))
  # Return subject results in the vector row
  return(row)  
}
```

```{r}
# Create results data frame
getResults = function(df) {
  # Create cols vector
  cols = c("subject", "online_id", "age", "accuracy", "accuracy_no_control",
           "missed_trials", 
           "control_rt_mean", "control_rt_sd", "control_acc",
           "control_missed", "control_rt_mean_incorrect", 
           "control_face_inversion", "control_up_rt_mean",
           "control_down_rt_mean", "control_log_rt_mean", 
           "control_log_rt_sd", "control_log_face_inversion", 
           "control_log_up_rt_mean", "control_log_down_rt_mean",
           
           "10Where_rt_mean", "10Where_rt_sd", "10Where_acc",
           "10Where_missed", "10Where_rt_mean_incorrect",
           "10Where_face_inversion", "10Where_up_rt_mean",
           "10Where_down_rt_mean", "10Where_log_rt_mean", 
           "10Where_log_rt_sd", "10Where_log_face_inversion", 
           "10Where_log_up_rt_mean", "10Where_log_down_rt_mean",
           
           "6Where_rt_mean", "6Where_rt_sd", "6Where_acc", "6Where_missed", 
           "6Where_rt_mean_incorrect",  "6Where_face_inversion",
           "6Where_up_rt_mean", "6Where_down_rt_mean", 
           "6Where_log_rt_mean", "6Where_log_rt_sd", 
           "6Where_log_face_inversion", "6Where_log_up_rt_mean", 
           "6Where_log_down_rt_mean",
           
           "6What_rt_mean", "6What_rt_sd", "6What_acc", "6What_missed", 
           "6What_rt_mean_incorrect", "6What_face_inversion", 
           "6What_up_rt_mean", "6What_down_rt_mean", "6What_log_rt_mean", 
           "6What_log_rt_sd", "6What_log_face_inversion", 
           "6What_log_up_rt_mean", "6What_log_down_rt_mean",
           
           "10What_rt_mean", "10What_rt_sd", "10What_acc", "10What_missed",
           "10What_rt_mean_incorrect", "10What_face_inversion", 
           "10What_up_rt_mean", "10What_down_rt_mean", "10What_log_rt_mean",
           "10What_log_rt_sd", "10What_log_face_inversion", 
           "10What_log_up_rt_mean", "10What_log_down_rt_mean")
  # init results data frame  
  result_df = data.frame(matrix(NA, ncol=71))
  # Set columns names by cols vector
  colnames(result_df) = cols
  # Set row_count variable
  row_count = 0
  # For each subject
  for(subject in unique(df$subject)) {
    # Add subject row (result of getSingleSubject) to results data frame
    result_df[row_count + 1, ] = getSingleSubject(df, subject)
    # Increase row count by 1
    row_count = row_count + 1
  }
  # Return results data frame
  return(result_df)
}
```

```{r}
# Set results data frame in results_df variable
results_df = getResults(prev_df)
# Print row count of results df
print(nrow(results_df))
```

```{r}
# Init bad online ids vector
bad_online_ids = c()
# Init current_df variable
current_df = data.frame()
# For each subject
for(subject in unique(results_df$subject)) {
  # Check if results contains BPQ questionnaire, if not its mean the
  # subject did not finish the experiment and will be excluded
  current_df = prev_df[(prev_df$subject == subject) & 
                         (nchar(prev_df$responses) == 151),]
  # If BPQ does not exist
  if(nrow(current_df) == 0) {
    # Add his online_id to 
    bad_online_ids = c(bad_online_ids, 
                       results_df[results_df$subject == subject,]
                       [1,"online_id"])
  }
}
```

```{r}
# Bad online ids vector, as decided by the author
bad_online_ids = c(bad_online_ids, "5c239f96da51990001e21d97",
                   "614e028cce0c68ed60059ab1", "55b0029bfdf99b5c00619440",
                   "614e149fccc6a53ae06dfcd2", "5d227f901e99f80018c60e1f")

# Remove bad online ids
results_df = results_df[!(results_df$online_id %in% bad_online_ids),]

# Print results data frame row count
print(nrow(results_df))
```

```{r}
# Remove under threshold 0.75% accuracy
results_df = results_df[results_df$accuracy > 0.75, ]

# Print results data frame row count
print(nrow(results_df))
```

```{r}
# Set results_df to numeric
results_df[] <- lapply(results_df, function(x) as.numeric(x))

# Add scaled column for all blocks rt mean
results_df$scaled_control_rt_mean = scale(results_df$control_rt_mean)
results_df$scaled_6What_rt_mean = scale(results_df[["6What_rt_mean"]])
results_df$scaled_6Where_rt_mean = scale(results_df[["6Where_rt_mean"]])
results_df$scaled_10what_rt_mean = scale(results_df[["10What_rt_mean"]])
results_df$scaled_10where_rt_mean = scale(results_df[["10Where_rt_mean"]])

# Remove subject with bigger or smaller by 3 SD from mean in each condition
results_df = results_df[abs(results_df$scaled_control_rt_mean) < 3, ]
results_df = results_df[abs(results_df$scaled_6What_rt_mean) < 3, ]
results_df = results_df[abs(results_df$scaled_6Where_rt_mean) < 3, ]
results_df = results_df[abs(results_df$scaled_10what_rt_mean) < 3, ]
results_df = results_df[abs(results_df$scaled_10where_rt_mean) < 3, ]

# Print results data frame row count
print(nrow(results_df))
```

## 2.3 [80 words; 5 points]

Inspect and describe the data set after the data cleaning and pre-processing 
procedure. Answer the following questions, and submit the lines of code that
helped you answer them 

### 2.3.1 

How many participants are left in the sample overall? 

67 Subjects

### 2.3.2

If trial-level task: How many trials are included per participant (and per 
condition, if applicable) on average?

```{r}
# Create data frame for compare in trial clean 
in_trial_clean_df = data.frame(matrix(NA, ncol=4))
# Set in_trial_clean_df_row_count to 0
in_trial_clean_df_row_count = 0
# Set columns names
colnames(in_trial_clean_df) = c("subject", "condition", "before", "after")
# For each subject
for(subject in unique(results_df$subject)) {
  # For each block
  for(block in blockNames) {
    # Create current row with subject and block
    in_trial_row = c(subject, block)
    # Create data frame of all trials in relevant subject and block
    b_df = prev_df[(prev_df$subject == subject) & 
                         (prev_df$stimulus_block == block),]  
    # Add row count of before data clean to in_trial_row
    in_trial_row = c(in_trial_row, nrow(b_df))
    # Add row count of after data clean to in_trial_row
    in_trial_row = c(in_trial_row, nrow(getCleanInTrialDf(b_df)))
    # Add in_trial_row to in_trial_clean_df
    in_trial_clean_df[in_trial_clean_df_row_count + 1, ] = in_trial_row
    # increase in_trial_clean_df_row_count by 1
    in_trial_clean_df_row_count = in_trial_clean_df_row_count + 1
  }
}
```

```{r}
# Set after column to numeric
in_trial_clean_df$after = as.numeric(in_trial_clean_df$after)

# calculating the mean amount of trials left after cleaning
print(mean(in_trial_clean_df$after[in_trial_clean_df$condition == "10Where"]))
print(mean(in_trial_clean_df$after[in_trial_clean_df$condition == "6Where"]))
print(mean(in_trial_clean_df$after[in_trial_clean_df$condition == "10What"]))
print(mean(in_trial_clean_df$after[in_trial_clean_df$condition == "6What"]))
print(mean(in_trial_clean_df$after[in_trial_clean_df$condition == 
                                                "10controlWhere"]))
```


### 2.3.3

If longitudinal data: How many time-points are included per participant (and per condition, if applicable) on average?

Not longitudinal

### 2.3.4

What is the distribution of number of trials/time-points included by participant? Draw a histogram

```{r}
hist(in_trial_clean_df$after
     [in_trial_clean_df$condition == "10Where"])
hist(in_trial_clean_df$after
     [in_trial_clean_df$condition == "10What"])
hist(in_trial_clean_df$after
     [in_trial_clean_df$condition == "6Where"])
hist(in_trial_clean_df$after
     [in_trial_clean_df$condition == "6What"])
hist(in_trial_clean_df$after
     [in_trial_clean_df$condition == "10controlWhere"])
```


## 2.4 [100 words; 4 points]

What was the statistical procedure previously employed on the data set to answer
the main theoretical question? Briefly describe the statistical test(s) in the context of the study.

ANOVA, t-test, correlation

## 2.5 [150 words; 10 points]

Given the sample size originally used, and the statistical procedure utilized, 
what was the study’s a priori statistical power3? Compute power for different population effect sizes that you deem as “small”, “medium”, and “large” in the context of your research domain. 
Given the power levels computed and the alpha used, and given what you see as a reasonable value for p(H1) / p(H0) odds (i.e., R), what is your estimate of the study’s PPV? For this section, you can assume that all test’s assumptions were met. You can use an off-the-shelf library for power calculations (e.g.,library(pwr)) or run a simulation. Submit the code and briefly describe your findings and their implications

```{r}
ppv_df = data.frame(matrix(NA, ncol = 4))
colnames(ppv_df) = c("test", "effect size", "power", "ppv")

reasonable_R = 0.6
sig_level = 0.05

calculate_ppv = function(R, power, a) {
  return((power * R) / ((power * R) + a))
}
```

```{r}
high_corr_power = pwr.r.test(n = 67, r = 0.6, sig.level = 0.05)
ppv_df[1, ] = c("corr", "high", high_corr_power$power, 
                calculate_ppv(reasonable_R, high_corr_power$power, sig_level))

# Cohen f = Cohen d / 2
high_anova_power = wp.rmanova(n = 67, ng = 2, nm = 2, f = 0.3, 
                              alpha = 0.05, type = 1)
ppv_df[2, ] = c("anova", "high", high_anova_power$power, 
                calculate_ppv(reasonable_R, high_anova_power$power, sig_level))

high_t_power = pwr.t.test(n = 67, d = 0.6, sig.level = 0.05,
                               type = c("paired"))
ppv_df[3, ] = c("t", "high", high_t_power$power, 
                calculate_ppv(reasonable_R, high_t_power$power, sig_level))

medium_corr_power = pwr.r.test(n = 67, r = 0.35, sig.level = 0.05)
ppv_df[4, ] = c("corr", "medium", medium_corr_power$power, 
                calculate_ppv(reasonable_R, medium_corr_power$power, sig_level))

# Cohen f = Cohen d / 2
medium_anova_power = wp.rmanova(n = 67, ng = 2, nm = 2, f = 0.175, 
                              alpha = 0.05, type = 1)
ppv_df[5, ] = c("anova", "medium", medium_anova_power$power, 
                calculate_ppv(reasonable_R, medium_anova_power$power, 
                              sig_level))

medium_t_power = pwr.t.test(n = 67, d = 0.35, sig.level = 0.05,
                               type = c("paired"))
ppv_df[6, ] = c("t", "medium", medium_t_power$power, 
                calculate_ppv(reasonable_R, medium_t_power$power, sig_level))

small_corr_power = pwr.r.test(n = 67, r = 0.15, sig.level = 0.05)
ppv_df[7, ] = c("corr", "small", small_corr_power$power, 
                calculate_ppv(reasonable_R, small_corr_power$power, sig_level))

# Cohen f = Cohen d / 2
small_anova_power = wp.rmanova(n = 67, ng = 2, nm = 2, f = 0.075, 
                              alpha = 0.05, type = 1)
ppv_df[8, ] = c("anova", "small", small_anova_power$power, 
                calculate_ppv(reasonable_R, small_anova_power$power, 
                              sig_level))

small_t_power = pwr.t.test(n = 67, d = 0.15, sig.level = 0.05,
                               type = c("paired"))
ppv_df[9, ] = c("t", "small", small_t_power$power, 
                calculate_ppv(reasonable_R, small_t_power$power, sig_level))

```

## 2.6 [250 words; 10 points]

Repeat the NHST statistical procedure originally conducted. Submit the code 
used. Summarize your findings (in your own words). You can (and are encouraged) to use a Table and a Figure (max 1 of each) to present the findings. Were you able to replicate the original findings? If not, discuss what might be the source of the differences.

```{r}
analysis_results_df = data.frame(matrix(NA, ncol = 7))
colnames(analysis_results_df) = c("index", "description", "type", 
                                  "effect_size", "p_value", 
                                  "CI_low", "CI_high")
```


### Analysis 1

Table: 6, 10 vs what, where

```{r}
# Create subset contains only the rt log means
analysis_1 = results_df[, c("6Where_rt_mean", "10Where_rt_mean",
                       "6What_rt_mean", "10What_rt_mean"),]

# Change columns name to prettier
colnames(analysis_1) = c("6Where", "10Where", "6What", "10What")

cor_value = cor.test(analysis_1[["6Where"]], analysis_1[["6What"]])
analysis_results_df[1, ] = c("1", "6Where 6What corr", "corr",
  cor_value$estimate, cor_value$p.value, cor_value$conf.int[1],
  cor_value$conf.int[2])
cor_value = cor.test(analysis_1[["6Where"]], analysis_1[["10What"]])
analysis_results_df[2, ] = c("1", "6Where 10What corr", "corr",
  cor_value$estimate, cor_value$p.value, cor_value$conf.int[1],
  cor_value$conf.int[2])
cor_value = cor.test(analysis_1[["10Where"]], analysis_1[["10What"]])
analysis_results_df[3, ] = c("1", "10Where 10What corr", "corr",
  cor_value$estimate, cor_value$p.value, cor_value$conf.int[1],
  cor_value$conf.int[2])
cor_value = cor.test(analysis_1[["10Where"]], analysis_1[["6What"]])
analysis_results_df[4, ] = c("1", "10Where 6What corr", "corr",
  cor_value$estimate, cor_value$p.value, cor_value$conf.int[1],
  cor_value$conf.int[2])
cor_value = cor.test(analysis_1[["10Where"]], analysis_1[["6Where"]])
analysis_results_df[5, ] = c("1", "10Where 6Where corr", "corr",
  cor_value$estimate, cor_value$p.value, cor_value$conf.int[1],
  cor_value$conf.int[2])
cor_value = cor.test(analysis_1[["10What"]], analysis_1[["6What"]])
analysis_results_df[6, ] = c("1", "10What 6What corr", "corr",
  cor_value$estimate, cor_value$p.value, cor_value$conf.int[1],
  cor_value$conf.int[2])

# Create corr plot
corrplot(cor(analysis_1), 
         p.mat=cor.mtest(analysis_1, conf.level = 0.95)$p, 
         method = 'color', diag = FALSE, type = 'upper',
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9,
         insig = 'label_sig', order = 'AOE')
```

### Analysis 2

```{r}
### preparing proper DF for RM ANOVA ###

# Create ANOVA df

anova_df = results_df
anova_df$BT_where_6Hz = results_df[["6Where_rt_mean"]]
anova_df$BT_where_10Hz = results_df[["10Where_rt_mean"]]
anova_df$BT_what_6Hz = results_df[["6What_rt_mean"]]
anova_df$BT_what_10Hz = results_df[["10What_rt_mean"]]

anova_df = anova_df[, c("subject", "BT_where_6Hz", "BT_where_10Hz", 
                        "BT_what_6Hz", "BT_what_10Hz")]

# Wide to long of ANOVA df
LongAnova_df <- wideToLong(data = anova_df, 
                           within = c("task", "hz"))

# Set factors and numeric to the relevant columns
LongAnova_df <- data.frame(subject = as.factor(x = LongAnova_df$subject),
                            task = as.factor(x = LongAnova_df$task),
                            hz = as.factor(x = LongAnova_df$hz),
                            BT = as.numeric(LongAnova_df$BT))

### analysis ###

# Create two way anova
twoWayAnovaRM <- aov(formula = BT ~ (task * hz) + 
                       Error(subject/(task * hz)),
                     data = LongAnova_df)

# Print model results
print(x = model.tables(x = twoWayAnovaRM,
                       type = "mean"))

# Summery Model
summary(twoWayAnovaRM)

anova_effect_size = eta_squared(twoWayAnovaRM, partial = T, alternative = "two")
for(i in 1:nrow(anova_effect_size)) {
  analysis_results_df[6 + i, ] = c("2", anova_effect_size[i, "Parameter"], 
                                   "anova", 
                                   anova_effect_size[i, "eta.sq.part"],
                                   anova_effect_size[i, "p"], 
                                   anova_effect_size$CI_low, 
                                   anova_effect_size$CI_high)
}

# Interaction graph
lineplot.CI(x.factor = LongAnova_df$task,
            response = LongAnova_df$BT,
            group = LongAnova_df$hz,
            col = c("chocolate1","chocolate4"),
            xlab = "task",
            ylab = "BT")

```

### Analysis 3

```{r}
# Create subset with 2 columns, all the what and all the where
analysis_t_task = data.frame(what = c(results_df[["6What_rt_mean"]],
                                      results_df[["10What_rt_mean"]]),
                             where = c(results_df[["6Where_rt_mean"]],
                                       results_df[["10Where_rt_mean"]]))

# T test for what and where
t_test_task = t.test(analysis_t_task$what, 
                           analysis_t_task$where, 
                           var.equal=TRUE,
                           paired = TRUE)

analysis_results_df[10, ] = c("3", "t test task", "t", 
                              cohensD(analysis_t_task$what,
                                      analysis_t_task$where,
                                      method = "paired"), 
                              t_test_task$p.value,
                              t_test_task$conf.int[1],
                              t_test_task$conf.int[2])
t_test_task
```



### Analysis 4

```{r}
# Create subset with 2 columns, all the 6 Hz and all the 10 Hz
analysis_t_hz = data.frame(six = c(results_df[["6What_rt_mean"]],
                                        results_df[["6Where_rt_mean"]]),
                                ten = c(results_df[["10What_rt_mean"]],
                                      results_df[["10Where_rt_mean"]]))

t_test_hz = t.test(analysis_t_hz$six, analysis_t_hz$ten, 
                   var.equal=TRUE, paired=T)

analysis_results_df[11, ] = c("3", "t test hz", "t", 
                                   cohensD(analysis_t_hz$six, 
                                           analysis_t_hz$ten,
                                           method = "paired"),
                              t_test_hz$p.value,
                              t_test_hz$conf.int[1],
                              t_test_hz$conf.int[2])
```


## 2.7 [250 words; 8 points]

Were effect size estimates and/or confidence intervals originally computed / reported? If yes, re estimate them using your own code. Plus, discuss whether additional estimates are required in your opinion, and if so, compute them. If not, choose and justify what estimates to include, and write a script that computes them. In both cases: Submit the code used, discuss the computed estimates, the justification behind their use, and discuss the implications of the estimates

```{r}
analysis_results_df
```


# Part 3: What could be done differently? [48 points overall]

## 3.1 [200 words; 10 points]

Discuss – is the procedure previously utilized proper for the data set at hand? Were any assumptions potentially violated by using this procedure? Are there any additional sources of variance not being accounted for by the method used (e.g., ignored random effects or control variables?)? Any other methodological issues related to the employed test? Critically discuss the identified issues. In parallel, inspect the data and try to demonstrate evidence for the potential issue(s) you’ve identified. Submit this code. If relevant, accompany your description with a figure.


```{r}
# Load data file
new_df = read.csv("data.csv")
```

```{r}
new_df$stimulus_block[new_df$stimulus_block == "5Where"] = "6Where"
new_df$stimulus_block[new_df$stimulus_block == "5What"] = "6What"
blockNamesWithoutControl = c('10Where', '6Where','6What', '10What')
```

```{r}
new_df = getSubjectAndCorrectness(new_df)
```

```{r}
getCleanedInTrialNewDf = function(df, sd_num=3) {
  return_df = data.frame(matrix(NA, ncol=5))
  first = T
  colnames(return_df) = c("subject","rt", "task", "hz", "inverted")
                        
  for(subject in unique(df$subject)) {
    for(single_hz in unique(df$hz)) {
      for(single_task in unique(df$task)) {
        temp_df = df[(df$subject == subject) &
                      (df$hz == single_hz) & 
                      (df$task == single_task), ]
        temp_df$scaled_rt = scale(temp_df$rt)
        temp_df = temp_df[abs(temp_df$scaled_rt) < sd_num, ]
        if(first) {
          return_df = temp_df[, c("subject","rt", "task", 
                                      "hz", "inverted")]
          first = F
        } else {
          return_df = rbind(return_df, 
                          temp_df[, c("subject","rt", "task", 
                                      "hz", "inverted")])
        }
      }
    }
  }
  
  return(return_df)
}
```

```{r}
old_results_df = getResults(prev_df)
old_results_df = old_results_df[old_results_df$online_id 
                                %in% bad_online_ids,]
new_bad_subjects = c(unique(old_results_df$subject))
```

```{r}
getNewRemovedSubject = function(df) {
  remove_subjects = c()
  for(subject in unique(df$subject)) {
    subject_df = df[df$subject == subject, ]
    where_10_df = subject_df[(subject_df$task == "Where") & 
                               (subject_df$hz == "10"), ]
    where_6_df = subject_df[(subject_df$task == "Where") & 
                              (subject_df$hz == "6"), ]
    what_10_df = subject_df[(subject_df$task == "What") & 
                              (subject_df$hz == "10"), ]
    what_6_df = subject_df[(subject_df$task == "What") & 
                             (subject_df$hz == "6"), ]
    where_10_accuracy = getAccResult(where_10_df)
    where_6_accuracy = getAccResult(where_6_df)
    what_10_accuracy = getAccResult(what_10_df)
    what_6_accuracy = getAccResult(what_6_df)
    if ((where_10_accuracy < 0.9) || 
        (where_6_accuracy < 0.85) || 
        (what_10_accuracy < 0.85) || 
        (what_6_accuracy < 0.8)) {
      remove_subjects = c(remove_subjects, subject)
    }
  }
  return(remove_subjects)
}
```

```{r}
getNewResult = function(bad_subject_list = c()) {
  new_results_df = new_df[, c("subject","rt", "stimulus_block", "stimulus", "isAnsCorrect")]
  new_results_df = new_results_df[
    new_results_df$stimulus_block %in% blockNamesWithoutControl, ]
  
  new_results_df$hz = apply(new_results_df, 1, 
                            FUN = function(row) {
    if(startsWith(row["stimulus_block"], "10"))
      return("10") else return("6")}) 
  
  new_results_df$task = apply(new_results_df, 1, FUN = function(row) {
    if(endsWith(row["stimulus_block"], "Where")) return("Where") 
    else return("What")
  }) 
  
  new_results_df$inverted = apply(new_results_df, 1, FUN = function(row)
    if(startsWith(row["stimulus"], "f")) "straight" else "inverted")
  
  new_results_df = new_results_df[
      !(new_results_df$subject %in%
          bad_subject_list),]
  
  remove_subjects = getNewRemovedSubject(new_results_df)
  
  new_results_df = new_results_df[
      !(new_results_df$subject %in%
          remove_subjects),]
  
  new_results_df = new_results_df[new_results_df$isAnsCorrect == 1, ]
  
  new_results_df = new_results_df[, c("subject","rt", "task", 
                                      "hz", "inverted")]
  
  new_results_df$rt = as.numeric(new_results_df$rt)
  
  # Return results data frame
  return(new_results_df)
}
```

```{r}
new_results_df = getNewResult(new_bad_subjects)
clean_df = getCleanedInTrialNewDf(new_results_df)
```

```{r}
model_df = clean_df

model_df$task = as.factor(model_df$task)
model_df$hz = as.factor(model_df$hz)
model_df$inverted = as.factor(model_df$inverted)

contrasts(model_df$task)[1] = -1
contrasts(model_df$hz)[1] = -1
contrasts(model_df$inverted)[1] = -1

model_df$rt = log(model_df$rt)
```


## 3.2 [200 words; 8 points]

Identify (some type of) a mixed-effect model analysis that can be used to 
analyze the data and address at least one of the issues discussed in 3.1. 
Fully describe the planned analysis and all pre processing steps it requires
(e.g., transformations, coding, random effect determination method,
etc.). Write a brief ‘analysis’ section (as if you are reporting your 
analysis plans in a paper/preregistration), containing all these details.
Also submit the code that instantiates these preparatory steps on your data.
Your mixed-effect model should contain at least two predictors, and in any case should address the work’s theoretical question and the issues you’ve identified 
in 3.1 above. 

```{r}
head(model_df)
```


```{r}
mixed_model = lmer(rt ~ task * hz + inverted + 
                          (1 + task * hz + inverted | subject), model_df)
tab_model(mixed_model, show.stat = T,show.df = T)
```
```{r}
summary(mixed_model)
```


## 3.3 [200 words; 10 points]

Run the mixed-effect model. Submit the code used to run it. Describe your 
findings, as if you are reporting it in a paper. You can add a Table and/or a Figure (max. 1 of each).

## 3.4 [150 words; 10 points]

Discuss how the results of the mixed-effect analysis compare to those originally observed/reported (using the “classic” tests). Do these differences (or lack thereof) fit your expectations? Are they in line with general differences between the two analytical approaches? Discuss what may have contributed to differences/similarities you observe.

## 3.5 [150 words; 10 points]

Assuming that the population effect size is the one observed in the mixed-effect analysis of the current data set, conduct a prospective power analysis for a replication study. We encourage you to use the simR package to circumvent needing complex simulations for this section4. What is the power of a replication with an identical sample size (and all other design properties)? If you think this power is too low or too high: What is the sample size needed to result in what you see as reasonable power? Submit the code used to run the power analysis, and describe what you found. You can accompany your description with a Figure. Do these results change your data collection plans as you prepare for your next study?

