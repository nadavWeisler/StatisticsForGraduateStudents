Statistics Ex2
Nadav Weisler: 316493758
Gaya Aran: 209636885

```{r}
set.seed(6)
```

```{r}
require(pwr)
require(dplyr)
```


# Question 1

## a

```{r}
get_q1_simulation = function(n = 47, std = 1.3) {
    sim_2way_anova = data.frame(
    dv=c(
      rnorm(n, mean = 2.9, sd = std),
      rnorm(n, mean = 2.3, sd = std),
      rnorm(n, mean = 2, sd = std),
      rnorm(n, mean = 1.8, sd = std),
      rnorm(n, mean = 2, sd = std),
      rnorm(n, mean = 1.8, sd = std)
    ),
    correction = c(rep("source",n),
              rep("no_source",n),
              rep("no_correction",n),
              rep("source",n),
              rep("no_source",n),
              rep("no_correction",n)),
    
    group = c(rep("control",n * 3),
              rep("thinkFRE",n * 3))
  )
  return(sim_2way_anova)
}

```

## b

```{r}
get_interaction_p_val_from_sim = function(sim_2way_anova) {
  aov_sim = aov(dv ~ correction * group, data = sim_2way_anova)
  interaction_p_val = summary(aov_sim)[[1]][["Pr(>F)"]][3]
  return(interaction_p_val)
}
```
## c

```{r}
p_val_df= data.frame(interaction_p_val = c())
for (i in 1:2000) {
  p_val = get_interaction_p_val_from_sim(get_q1_simulation())
  p_val_df = rbind(p_val_df, data.frame(interaction_p_val = p_val)) 
}

powerValue = mean(p_val_df$interaction_p_val < 0.05)
paste("Simulation Power: ", powerValue)
```

# Question 2

The plot showed us that as the R value gets greater, so does the PPV.

```{r}
calculate_ppv = function(R, B, a) {
  return(((1 - B) * R) / (((1 - B) * R) + a))
}

ppv_df = data.frame(ppv = c())
for (R in c(0.2, 0.4, 0.6, 0.8)) {
    ppv_df = rbind(ppv_df, data.frame(PPV = calculate_ppv(R, powerValue, 0.05), 
                                      R = R)) 
}

plot(ppv_df)
```

# Question 3

The approximate group size we need is 109 Subjects.

```{r}
p_val_df_2 = data.frame(interaction_p_val = c())
for (i in 1:2000) {
  p_val = get_interaction_p_val_from_sim(
    get_q1_simulation(n = 109))
  p_val_df_2 = rbind(p_val_df_2, data.frame(interaction_p_val = p_val)) 
}

powerValue = mean(p_val_df_2$interaction_p_val < 0.05)
paste("POWER: ", powerValue)
```

# Question 4

As can be seen in the histogram, the data does not distribute normally 
(it is a skewed distribution). In our simulation we assumed normality, 
which doesn't match what the data looks like.

```{r}

df_study_2 = read.csv("data_study2.csv")
df_study_2 = df_study_2[-(1:1),]
df_study_2$mainDV_sterility <- as.numeric(df_study_2$mainDV_sterility)
hist(df_study_2$mainDV_sterility, 
     xlab = "DV Sterility", 
     main = "DV Sterility Histogram")

```

# Question 5

25 Subjects were excluded after cleaning.

## a

```{r}
df_study_2 = df_study_2[!is.na(df_study_2$Group),]
df_study_2 = df_study_2[!is.na(df_study_2$Correction),]
df_study_2 = df_study_2[!is.na(df_study_2$mainDV_sterility),]
```

## b

```{r}
df_study_2 = df_study_2[df_study_2$exclusion == 0,]
```

## c

```{r}
z_scores_df <- mutate(df_study_2 %>% group_by(Group, Correction), z_scores = 
                        as.numeric(scale(mainDV_sterility))) %>% 
  filter(abs(z_scores) < 3)
```


# Question 6

We learn that there is a great difference in the variances of two group out of
the six (first 2 in the DF). One of the assumptions we use in order to compute 
two-way ANOVA is the homogeneity of variance, which does not totally apply here.

```{r}
grouped_df_study_2 <- df_study_2 %>%
  group_by(Group, Correction) %>%
    summarise(
      variance = var(mainDV_sterility)
    )

grouped_df_study_2
```


# Question 7

The main effect between the control group and the treatment group in relation 
to the dependent variable was found to be significant (p value = 0.0026), with 
an effect size: partial eta 2 = 0.03. The main effect between the types of 
corrections was not significant (p value = 0.052), and the partial eta 2 = 0.02.
The interaction effect between the two levels (group and corrections) in 
relation to the dependent variable was found to be significant 
(p value = 0.019), and partial eta 2 = 0.03.

```{r}
df_study_2$Group <- as.factor(df_study_2$Group)
df_study_2$Correction <- as.factor(df_study_2$Correction)

study_2_anova = aov(mainDV_sterility~Group*Correction, data = df_study_2)
summary(study_2_anova)

effectsize::eta_squared(study_2_anova)
```

# Question 8

The hypothesis of the researchers was that an effect of the manipulation is 
different in one type of correction compared to the others, and a distinct 
interaction effect was found. Meaning - the null hypothesis that there is no 
difference between the groups in relation to the effect of the type of 
correction on the belief that a corona vaccine causes infertility can be 
rejected. In the graph we created you can see that the correction that shows 
the most change between the control group and the treatment group - is actually
the baseline, the one in which no correction was made at all. I will address 
the implications of this understanding and the follow-up tests required in the
next question.

```{r}
require(sciplot)

lineplot.CI(x.factor = df_study_2$Group,
  response = df_study_2$mainDV_sterility,
  group = df_study_2$Correction,
  col = c("brown","green", "pink"),
  xlab = "Group (0 - Control, 1 - ThinkFRE)",
  ylab = "Sterility",
  legend = TRUE,
  leg.lab = c("Correction with sci. source", 
              "Correction without source",
              "Baseline (no correction)"),
  x.leg = "topright"
)
```

# Question 9

What is actually missing in order to check if the researchers' exact 
hypothesis, in relation to the effect of treatment on disbelief with the 
correction of scientific source, is a test of contrasts and comparisons. 
Currently, without further analysis, we only found that there is an interaction
effect and we did not specify the p value in relation to the priory hypothesis
of the researchers. What was expected to be done is planned contrasts before
running the experiment, as well as post-hoc contrasts to check how the p value
and weights actually changed after collecting the data.

# Question 10

The two-way-Anova model is constructed so that the variables added to the model
may affect each others significance. In this case, it can be seen that a 
one-way ANOVA for each of the categories led to less significance. 
Hence, in the two-way Anova model there was probably more variance explained 
through the combination of several categories and their interaction.

```{r}
one_way_anova_1 = aov(mainDV_sterility~Group, data = df_study_2)
one_way_anova_2 = aov(mainDV_sterility~Correction, data = df_study_2)
summary(one_way_anova_1)
summary(one_way_anova_2)

```


